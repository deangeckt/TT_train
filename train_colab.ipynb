{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup environment"
      ],
      "metadata": {
        "id": "7ICLkz4W648B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/TT_train"
      ],
      "metadata": {
        "id": "vF1Et82F5i8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Myln5AO5YN_a"
      },
      "source": [
        "# Reading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hbn-lUq0YN_p",
        "outputId": "830dac19-2e4c-46a3-994b-a0228f31d62f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "orignal data sizes: train size: 1071 test size: 150 val size: 150\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from utils.split_sets import load_data\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "x_train, x_test, x_val, y_train, y_test, y_val, metadata_train, metadata_test, metadata_val = load_data('fts')\n",
        "print(f'orignal data sizes: train size: {x_train.shape[0]} test size: {x_test.shape[0]} val size: {x_val.shape[0]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-s9oaDuYN_7"
      },
      "outputs": [],
      "source": [
        "def print_set_labels(y_set, name):\n",
        "    unique, counts = np.unique(y_set, return_counts=True)\n",
        "    for idx, c in enumerate(counts):\n",
        "        print(f'{name}: label: {idx}: {c} samples')\n",
        "\n",
        "print_set_labels(y_train, 'y_train')\n",
        "print_set_labels(y_test, 'y_test')\n",
        "print_set_labels(y_val, 'y_test')\n",
        "print('\\ntrain data still un balanced!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFSq4cFpYN__"
      },
      "source": [
        "# Augmentation + Upsampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFQ_LZtkYOAE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from utils.general import rand_shot\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def stack_data(data_pos_, data_neg_, data_new, stack_foo):\n",
        "    '''\n",
        "    stack x,y, metadata at the same fashion such that the indices will align\n",
        "    '''\n",
        "    data_pos_ = stack_foo((data_pos_, data_new))\n",
        "    return stack_foo((data_pos_, data_neg_))\n",
        "\n",
        "\n",
        "frame_prob = 1\n",
        "\n",
        "pos = np.where(y_train==1)\n",
        "neg = np.where(y_train==0)\n",
        "\n",
        "metadata_pos = metadata_train[pos]\n",
        "metadata_neg = metadata_train[neg]\n",
        "\n",
        "data_pos = x_train[pos]\n",
        "data_neg = x_train[neg]\n",
        "\n",
        "y_pos = y_train[pos]\n",
        "y_neg = y_train[neg]\n",
        "\n",
        "up_sample_amount = len(neg[0]) - len(pos[0])\n",
        "print(f'generating {up_sample_amount} shots')\n",
        "\n",
        "new_data = []\n",
        "new_metadata = []\n",
        "new_y = np.ones(up_sample_amount)\n",
        "\n",
        "rand_amount = 0\n",
        "run_ = True\n",
        "\n",
        "with tqdm(total=up_sample_amount) as pbar:\n",
        "    while run_:\n",
        "        for shot_idx, shot in enumerate(data_pos):\n",
        "            amount = metadata_pos[shot_idx]['frames']\n",
        "            name = metadata_pos[shot_idx]['name']\n",
        "            new_shot = rand_shot(shot, amount, frame_prob=frame_prob)\n",
        "            \n",
        "            new_metadata.append({'name': f'{name}_rand_{rand_amount}', 'frames': amount})\n",
        "            new_data.append(new_shot)\n",
        "            \n",
        "            rand_amount += 1 \n",
        "            pbar.update(1)\n",
        "            \n",
        "            if rand_amount == up_sample_amount:\n",
        "                run_ = False\n",
        "                break\n",
        "\n",
        "new_data_pos = torch.stack([shot for shot in new_data])\n",
        "\n",
        "x_train = stack_data(data_pos, data_neg, new_data_pos, torch.vstack)\n",
        "y_train = stack_data(y_pos, y_neg, new_y, np.concatenate)\n",
        "metadata_train = stack_data(metadata_pos, metadata_neg, new_metadata, np.concatenate)\n",
        "\n",
        "print('x train shape', x_train.shape)\n",
        "print_set_labels(y_train, 'y_train')\n",
        "print('\\ntrain data is now balanced!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hg0-AyoHYOAL"
      },
      "source": [
        "# Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWIgIQ_vYOAQ"
      },
      "outputs": [],
      "source": [
        "def feature_selection(x_set, remove_features):\n",
        "    idxs = []\n",
        "    for p in remove_features:\n",
        "        idxs.extend(list(range(p*4, p*4 + 4)))\n",
        "    return np.delete(x_set, idxs, axis=2)\n",
        "\n",
        "head_landmarks = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "\n",
        "remove_landmarks = []\n",
        "x_train = feature_selection(x_train, remove_landmarks)\n",
        "x_test = feature_selection(x_test, remove_landmarks)\n",
        "x_val = feature_selection(x_val, remove_landmarks)\n",
        "\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(x_val.shape)\n",
        "\n",
        "\n",
        "NUM_FEATURES = 100 - (len(remove_landmarks) * 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9qEUxebYOAZ"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-7EQZKavYOAg"
      },
      "outputs": [],
      "source": [
        "## Network\n",
        "HIDDEN_DIM = 64\n",
        "OUTPUT_DIM = 2\n",
        "BATCH_SIZE = 32\n",
        "IS_BID = True\n",
        "NUM_LAYERS = 2\n",
        "\n",
        "## Optimizer  \n",
        "lr = 1e-3/5\n",
        "weight_decay=0.001\n",
        "\n",
        "## Scheduler\n",
        "step_size=10\n",
        "gamma=0.5\n",
        "\n",
        "early_stop_patience = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoSogFUeYOAn"
      },
      "source": [
        "# Data Set & Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZqUlbXyYOAu",
        "outputId": "c4574851-c5c0-46ec-9dec-a9c432274a04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data sizes: train size: 1906 val size: 150 test size: 150\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "train_labels = pd.DataFrame({'label': y_train, 'metadata': metadata_train})\n",
        "val_labels = pd.DataFrame({'label': y_val, 'metadata': metadata_val})\n",
        "test_labels = pd.DataFrame({'label': y_test, 'metadata': metadata_test})\n",
        "\n",
        "\n",
        "print(f'data sizes: train size: {x_train.shape[0]} val size: {x_val.shape[0]} test size: {x_test.shape[0]}')\n",
        "\n",
        "\n",
        "class TTDataset(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels.iloc[idx]['label'], idx\n",
        "\n",
        "def create_dataloaders(batch_size):\n",
        "    train_data = TTDataset(x_train, train_labels)\n",
        "    test_data = TTDataset(x_test, test_labels)\n",
        "    validation_data = TTDataset(x_val, val_labels)\n",
        "    \n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "    validation_loader = DataLoader(validation_data, batch_size=1, shuffle=True)\n",
        "    test_loader = DataLoader(test_data, batch_size=1, shuffle=False)\n",
        "    \n",
        "    return train_loader, validation_loader, test_loader\n",
        "\n",
        "    \n",
        "train_loader, validation_loader, test_loader = create_dataloaders(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpZsr-ZaYOAy"
      },
      "source": [
        "# Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oWPJ0Pz2YOA0"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.scale = 1. / math.sqrt(hidden_size)\n",
        "\n",
        "    def forward(self, hidden, outputs):\n",
        "        hidden = hidden.unsqueeze(1)\n",
        "        weights = torch.bmm(hidden, outputs.transpose(1, 2))\n",
        "\n",
        "        scores = F.softmax(weights.mul_(self.scale), dim=2)\n",
        "        linear_combination = torch.bmm(scores, outputs).squeeze(1)\n",
        "        return linear_combination\n",
        "\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self, input_dim, h_dim, out_dim, num_layers,\n",
        "                 bidirectional=True, use_attention=True):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.h_dim = h_dim\n",
        "        self.bidirectional = bidirectional\n",
        "        self.use_attention = use_attention\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "        hid_bidirectional = h_dim * 2 if bidirectional else h_dim\n",
        "        self.atten = Attention(hid_bidirectional)\n",
        "\n",
        "        # LSTM\n",
        "        self.lstm = nn.LSTM(input_size=input_dim,\n",
        "                            hidden_size=h_dim,\n",
        "                            num_layers=num_layers,\n",
        "                            bidirectional=bidirectional, batch_first=True, dropout=0.5)\n",
        "        # FC layer\n",
        "        self.fc = nn.Linear(hid_bidirectional, out_dim, bias=True)\n",
        "\n",
        "        # To convert class scores to log-probability we'll apply log-softmax\n",
        "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, X, batch_size):\n",
        "        lay_times_dir = self.num_layers * 2 if self.bidirectional else self.num_layers\n",
        "        h0 = torch.zeros(lay_times_dir, batch_size, HIDDEN_DIM).to(device)\n",
        "        c0 = torch.zeros(lay_times_dir, batch_size, HIDDEN_DIM).to(device)\n",
        "\n",
        "        out, (h_t, c_t) = self.lstm(X, (h0, c0))\n",
        "        if self.bidirectional:\n",
        "            cell_state = torch.cat([c_t[-1], c_t[-2]], dim=1)\n",
        "        else:\n",
        "            cell_state = c_t[-1]\n",
        "        \n",
        "        classify_input = self.atten(cell_state, out) if self.use_attention else cell_state\n",
        "        y = self.fc(classify_input)\n",
        "        \n",
        "        yt_log_proba = self.log_softmax(y)\n",
        "        return yt_log_proba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhRgyWJTYOA7",
        "outputId": "074c307d-56d1-4a0e-e3ba-64a3044b533f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cpu')\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "4AijwvfMYOA-"
      },
      "outputs": [],
      "source": [
        "from utils.learn import train_model\n",
        "\n",
        "# frame_prob = 0\n",
        "use_attention = True\n",
        "model = Network(NUM_FEATURES, HIDDEN_DIM, OUTPUT_DIM, NUM_LAYERS, \n",
        "                bidirectional=IS_BID, use_attention=use_attention).to(device)\n",
        "\n",
        "features_name = 'all_features' if NUM_FEATURES == 100 else 'no_head'\n",
        "aug_name = 'with_aug' if frame_prob > 0 else 'no_aug'\n",
        "att_name = 'with_attn' if use_attention else 'no_attn'\n",
        "model_name = f'b{BATCH_SIZE}_lr{lr}_sz{step_size}_g{gamma}_h{HIDDEN_DIM}_nl{NUM_LAYERS}_{features_name}_{aug_name}_{att_name}.pt'\n",
        "print(model_name)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "loss_fn = nn.NLLLoss()\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "train_model(model, model_name, BATCH_SIZE, device, early_stop_patience,\n",
        "            train_loader, validation_loader, test_loader,\n",
        "            optimizer, scheduler, loss_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-Cn3eNlYOBE"
      },
      "source": [
        "# False analysis "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AT-FuqeXYOBF"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score, accuracy_score\n",
        "from utils.learn import predict\n",
        "from visualization import points_visualization\n",
        "from IPython.display import Image\n",
        "\n",
        "model.load_state_dict(torch.load('model_results/' + model_name))\n",
        "model.eval()\n",
        "correct_idx, wrong_idx, y_pred, y_true, confs = predict(model, test_loader, device, 1, 0.0)\n",
        "print('prec', precision_score(y_true, y_pred))\n",
        "print('acc', accuracy_score(y_true, y_pred))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred, labels=[0,1] )#normalize='true')\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sx3OXUpNYOBK"
      },
      "outputs": [],
      "source": [
        "# print('correct', correct_idx)\n",
        "print('wrong', wrong_idx)\n",
        "print()\n",
        "\n",
        "debug_idx = 22\n",
        "debug_name = test_labels.iloc[debug_idx]['metadata']['name']\n",
        "debug_amount = test_labels.iloc[debug_idx]['metadata']['frames']\n",
        "\n",
        "debug_X = x_test[debug_idx]\n",
        "\n",
        "print('debug original idx in test set: ', debug_idx)\n",
        "print('true label:', test_labels.iloc[debug_idx]['label'])\n",
        "print('correct:', debug_idx in correct_idx)\n",
        "print('shot name: ', debug_name)\n",
        "print('frames', debug_amount)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "KhIJqE58YOBP"
      },
      "outputs": [],
      "source": [
        "points_visualization.create_landmarks_gif(debug_name, debug_X, debug_amount, remove_landmarks)\n",
        "with open(f'visualization/shots_3d_demo/{debug_name}.gif','rb') as f:\n",
        "    display(Image(data=f.read(), format='png', width=500, height=500))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYv92a0VYOBS"
      },
      "outputs": [],
      "source": [
        "splitted = debug_name.split('_')\n",
        "shot_type = splitted[0]\n",
        "splitted = splitted[0:len(splitted)-1]\n",
        "shot_folder = '_'.join(splitted)\n",
        "vid_path = f'{shot_type}/{shot_folder}'\n",
        "\n",
        "gif_name = f'real_{debug_name}'\n",
        "points_visualization.create_vid_gif(vid_path, debug_name, debug_amount)\n",
        "with open(f'visualization/shots_3d_demo/{gif_name}.gif','rb') as f:\n",
        "    display(Image(data=f.read(), format='png', width=350, height=450))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "name": "train_colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}