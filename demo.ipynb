{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11221b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "from train import TTDataset, Network, HIDDEN_DIM, OUTPUT_DIM, IS_BID, NUM_LAYERS\n",
    "from shot_extractor.pose_extractor import shotsExtractor\n",
    "from utils.general import read_raw_data\n",
    "from utils.learn import predict\n",
    "\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "print('device', device)\n",
    "\n",
    "NUM_FEATURES = 100\n",
    "model = Network(NUM_FEATURES, HIDDEN_DIM, OUTPUT_DIM,\n",
    "                bidirectional=IS_BID, num_layers=NUM_LAYERS,\n",
    "                use_attention=True, device=device).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('model_results/fts_best.pt'))\n",
    "model.eval()\n",
    "\n",
    "print('Model loaded to memory')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d0ce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = shotsExtractor(mv_wd=3, mv_th=0.6, shots_delta=3,\n",
    "                     min_length=6, file_name='fco_rt', e2e=True)\n",
    "\n",
    "single_pose_data = ['x', 'y', 'z', 'vis']\n",
    "pose_columns = []\n",
    "for i in range(0, shotsExtractor.pose_max_idx + 1):\n",
    "    pose_columns.extend(['{}_{}'.format(i, key) for key in single_pose_data])\n",
    "\n",
    "data_df = pd.DataFrame(columns=pose_columns)\n",
    "score_df = pd.DataFrame(columns=['score', 'shot', 'frames'])\n",
    "\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    success, img = vid.read()\n",
    "    if not success:\n",
    "        break\n",
    "    pos.process(img)\n",
    "\n",
    "    cv2.imshow('Vid', img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "pos.save_shots_labeled_csv(score_df, data_df)\n",
    "score_df.index.name = 'name'\n",
    "x, y_none, metadata = read_raw_data(score_df, data_df, e2e=True)\n",
    "labels = pd.DataFrame({'label': y_none, 'metadata': metadata})\n",
    "\n",
    "amount = len(metadata)\n",
    "print(f'{amount} shots extracted...')\n",
    "\n",
    "test_data = TTDataset(x, labels)\n",
    "test_loader = DataLoader(test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "_, _, y_pred, _, confs = predict(model, test_loader, device, 1, 0.95)\n",
    "\n",
    "for i, (p, c) in enumerate(zip(y_pred, confs)):\n",
    "    print(f'idx: {i} pred: {p} conf: {c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51971ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from visualization import points_visualization\n",
    "from IPython.display import Image\n",
    "\n",
    "y_pred = np.array(y_pred)\n",
    "debug_idx = 2\n",
    "shot_name = labels.iloc[debug_idx]['metadata']['name']\n",
    "amount = labels.iloc[debug_idx]['metadata']['frames']\n",
    "\n",
    "\n",
    "vid_path = 'fts/fts_rt'\n",
    "gif_name = f'real_{shot_name}'\n",
    "points_visualization.create_vid_gif(vid_path, shot_name, amount)\n",
    "with open(f'visualization/shots_3d_demo/{gif_name}.gif','rb') as f:\n",
    "    display(Image(data=f.read(), format='png', width=350, height=450))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
